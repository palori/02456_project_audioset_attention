{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How they do it in the Readme file ###\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def load_data(hdf5_path):\n",
    "    with h5py.File(hdf5_path, 'r') as hf:\n",
    "        x = hf.get('x')\n",
    "        y = hf.get('y')\n",
    "        video_id_list = hf.get('video_id_list')\n",
    "        x = np.array(x)\n",
    "        y = list(y)\n",
    "        video_id_list = list(video_id_list)\n",
    "        \n",
    "    return x, y, video_id_list\n",
    "\n",
    "def uint8_to_float32(x):\n",
    "    return (np.float32(x) - 128.) / 128.\n",
    "    \n",
    "def bool_to_float32(y):\n",
    "    return np.float32(y)\n",
    "\n",
    "path = '../packed_features/' #just if they can be found in other folders\n",
    "files = ['bal_train','eval'] #forget about the 'unbal_train'S\n",
    "extension = '.h5'\n",
    "data = {}\n",
    "for f in files:\n",
    "    \n",
    "    data[f] = {}\n",
    "    hdf5_path = path+f+extension\n",
    "    print('\\nReading data from: '+hdf5_path)\n",
    "    \n",
    "    (x, y, video_id_list) = load_data(hdf5_path)\n",
    "    x = uint8_to_float32(x)\t\t# shape: (N, 10, 128)\n",
    "    y = bool_to_float32(y)\t\t# shape: (N, 527)\n",
    "    data[f]['x'] = np.array(x)\n",
    "    data[f]['y'] = np.array(y)\n",
    "    data[f]['video_id_list'] = [str(v)[2:-1] for v in video_id_list]\n",
    "    \n",
    "    # print info\n",
    "    print('x',x.shape)\n",
    "    print('y',y.shape)\n",
    "    print('video id',len(video_id_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at some of the data\n",
    "for d in data.keys():\n",
    "    print('\\n\\n'+d+':')\n",
    "    params = ['x','y','video_id_list']\n",
    "    for p in params:\n",
    "        print('\\n'+p+':')\n",
    "        print(data[d][p][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v = data[list(data.keys())[1]][params[2]]\n",
    "find_id = '9OqtuFGCCR8'#'Sb0169-lqLs'\n",
    "#print(v.)\n",
    "for i in v:\n",
    "    if i == find_id:\n",
    "        print(i,' == '+find_id)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_dir_files(path, just_filename=True):\n",
    "    files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        if just_filename:\n",
    "            files.extend([file for file in filenames])\n",
    "        else:\n",
    "            direc = dirpath.split('/')[-1]\n",
    "            files.extend([direc+'/'+file for file in filenames])\n",
    "    print('get_dir_files\\nFiles: ',files)\n",
    "    return files\n",
    "\n",
    "audioset_path = '../packed_features/'\n",
    "audioset_files = get_dir_files(path=audioset_path, just_filename=True)\n",
    "audioset_files = [f for f in audioset_files if (f.split('.')[-1] == 'h5') and (f.split('_')[0] != 'unbal')]\n",
    "print(audioset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "h = pd.DataFrame()\n",
    "h['1']= [1,2,3]\n",
    "h['2']= [4,5,6]\n",
    "h['id']= ['a','b','c']\n",
    "h.set_index('id',inplace=True)\n",
    "print(h.head())\n",
    "\n",
    "j = pd.DataFrame()\n",
    "j['4']= [41,42,43]\n",
    "j['3']= [34,35,36]\n",
    "j['id']= ['a','b','d']\n",
    "j.set_index('id',inplace=True)\n",
    "print(j.head())\n",
    "\n",
    "result = pd.merge(h, j, on='id', how='inner')\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([[11,12,13], [31,32,33]])\n",
    "p = np.array([[21,22], [41,42]])\n",
    "print(q)\n",
    "print(p)\n",
    "print(np.concatenate((q.T, p.T), axis=0))\n",
    "print(np.concatenate((np.array([]),p), axis=None))\n",
    "a = pd.DataFrame()\n",
    "a['a'] = np.concatenate((q.T, p.T), axis=0)\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5_files(path, files, print_info=False):\n",
    "    #initialization of outputs\n",
    "    data = {}\n",
    "    pd_data = pd.DataFrame()\n",
    "    x_pd = np.array([])\n",
    "    y_pd = np.array([])\n",
    "    id_pd = np.array([])\n",
    "\n",
    "    for f in files:\n",
    "        data[f] = {}\n",
    "        hdf5_path = path+f\n",
    "        print('\\nReading data from: '+hdf5_path)\n",
    "        \n",
    "        (x, y, video_id_list) = load_data(hdf5_path)\n",
    "        x = np.array(uint8_to_float32(x))     # shape: (N, 10, 128)\n",
    "        y = np.array(bool_to_float32(y))      # shape: (N, 527)\n",
    "        video_id_list = np.array([str(v)[2:-1] for v in video_id_list]) # take just the ID\n",
    "\n",
    "        data[f]['x'] = x\n",
    "        data[f]['y'] = y\n",
    "        data[f]['id'] = video_id_list\n",
    "\n",
    "        #pd_data['x']\n",
    "        x_pd= np.concatenate((x_pd,x), axis=0)\n",
    "        y_pd= np.concatenate((y_pd,y), axis=0)\n",
    "        id_pd= np.concatenate((id_pd,id), axis=0)\n",
    "        #pd_data['y'] = np.concatenate((pd_data['y'],y), axis=None)\n",
    "        #pd_data['id'] = np.concatenate((pd_data['id'],video_id_list), axis=None)\n",
    "        \n",
    "        # print info\n",
    "        if print_info:\n",
    "            print('x',x.shape)\n",
    "            print('y',y.shape)\n",
    "            print('video id',len(video_id_list))\n",
    "    \n",
    "        print(x_pd.shape)\n",
    "        print(y_pd.shape)\n",
    "        print(id_pd.shape)\n",
    "        \n",
    "    \"\"\"\n",
    "    pd_data['x'] = x_pd\n",
    "    pd_data['y'] = y_pd\n",
    "    pd_data['id'] = id_pd\n",
    "    pd_data.set_index('id',inplace=True)\n",
    "    \"\"\"\n",
    "    return {'dict_data':data, 'pd_data':pd_data}\n",
    "    \n",
    "audioset_path = '../packed_features/'\n",
    "audioset_files = get_dir_files(path=audioset_path, just_filename=True)\n",
    "# Keep just the ones with extension .h5 and NOT unbalanced data!\n",
    "audioset_files = [f for f in audioset_files if (f.split('.')[-1] == 'h5') and (f.split('_')[0] != 'unbal')]\n",
    "print(audioset_files)\n",
    "audioset_data = read_h5_files(path=audioset_path, files=audioset_files, print_info=True)\n",
    "# because we want it in DataFrame and not as dict, see the function\n",
    "audioset_data = audioset_data['pd_data']\n",
    "audioset_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioset_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
